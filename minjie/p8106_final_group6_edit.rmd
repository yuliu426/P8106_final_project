---
title: "Final Project for Data Science II" 
author: "Group 6"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
--- 
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
library(tidyverse)
library(visdat)
library(caret)
library(arsenal)
library(missForest)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(randomForest)
library(ranger)
library(gbm)
library(e1071)
library(kernlab)
```


#Introduction
## Data Description
This dataset is designed to understand the factors that lead a person to leave current job. Information contained in the dataset are demographics(city, gender, etc), education(education level, major displine, etc), experience(experience, company size, etc) of employees. The outcome is the variable "target"(binary), where "0" represents the employee is not looking for job change while "1" represents the employee is looking for a job change. Using this dataset, we can predict the probability of a employee to look for a new job based on their demographic, edcation and experience information. 
The more specific information of the data can be found at [here](https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists).

```{r include=TRUE, message=FALSE}
job = read_csv("job/aug_train.csv") %>% select(-c(1,2))
```

## Data Preproccessing

### Predictors Selection             
There are 13 features in this dataset, but enrollee_id is not a predictor. What's more, a more meaningful way to assess the influence of a city is through its extend development, so I excluded "city" since we have "city_development_index" feature.

### Missing data            
According to the misssingness figure[figure1], "company_type" and "company_zise", "gender", "major_displine" has relatively large propotion of missingness. There are also some missingness in education_leval, enrolled_university, last_new_job and experience, but those missingness only account for a small proportion.
For the predictor that has small proportion of missingness, I simply droped the observations that has such missingess. For the four variable that has high proportion of missingness, I used missForest to do the imputation. Before doing the imputation, I tansfered all characters into factors.

```{r include=TRUE, message=FALSE}
Skimmed <- skimr::skim(job)

Skimmed %>% select(skim_variable, n_missing) %>%
  filter(n_missing != 0) %>%
  ggplot(aes(
    x = fct_reorder(skim_variable, n_missing),
    y = n_missing,
    label = n_missing,
    fill = skim_variable
  )) +
  geom_col() +
  geom_text(hjust = -0.3,
            color = "red",
            fontface = "bold.italic") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 7000)) +
  theme_light() +
  theme(legend.position = "none")
```


```{r include=TRUE, message=FALSE}
job =job%>% 
  drop_na(c(4, 5, 7, 10)) %>% 
  rename(relevant_experience = relevent_experience) %>% 
  mutate(target = recode_factor(target,
                                `1` = "change", `0` = "no_change" )) %>%  
  mutate_if(is.character, as.factor) %>% 
  as.data.frame()

summary(job)
```


```{r include=TRUE, message=FALSE}
set.seed(2021)

rowTrain = createDataPartition(y = job$target, 
                               p = 0.8,
                               list = FALSE)
dat_tr = job[rowTrain,]
dat_te = job[-rowTrain,]
```


```{r include=TRUE, message=FALSE}
set.seed(2021)
imputed_tr <- missForest(dat_tr, maxiter = 2, ntree = 20)
imputed_te <- missForest(dat_te, maxiter = 2, ntree = 20)


job_tr = imputed_tr$ximp
job_te = imputed_te$ximp
```


## Exploratory Analysis

```{r include=TRUE, message=FALSE}
tab <- tableby(target ~ relevant_experience +gender + enrolled_university+education_level+major_discipline+experience+company_size+company_type+last_new_job+gender, data=rbind(job_tr, job_te))
summary(tab, title = "Descriptive Statistics: Job Change",  text=T)
```

### Visualazation of categorical variables

For categorical data, I make the table to show the percentage of each level accounted for the two classes. From the descriptive statistics of catogorical data,there is no very explicit structure of the data.But from the table, we can see that, for some of the predictors there are various levels that could result in too many dummy variables in the following model build process. After carefully look into different levels and their percentage,I decided to make some data collapse to reduce some of the levels. I believe it could save some computing effort without severly hurt the prediction.

```{r include=TRUE, message=FALSE}
job_tr = job_tr %>% mutate(enrolled_university = case_when(
                                            enrolled_university == "no_enrollment" ~ "noEnroll",
                                            enrolled_university %in% c("Full time course", "Part time course") ~ "enrolled")) %>% 
              mutate(education_level = case_when(
                                        education_level %in% c("Masters", "Phd") ~ "aboveCollege",
                                        education_level %in% c("Primary School", "High School") ~ "noCollege",
                                        TRUE ~ "college")) %>% 
             mutate(major_discipline = case_when(
                                         major_discipline == "STEM" ~ "STEM",
                                         TRUE ~ "non_STEM")) %>% 
             mutate(experience = case_when(
                                  experience  == ">20" ~ "twenty",
                                  experience == "<1" ~ "one",
                                  TRUE ~ "oneTotwenty")) %>%
             mutate(company_size = case_when(
                                    company_size %in% c("<10","10/49","50-99","100-500") ~ "small",
                                    company_size %in% c("500-999","1000-4999", "5000-9999") ~ "medium",
                                    TRUE ~ "big"))%>% 
             mutate(last_new_job = case_when(
                                    last_new_job == "1" ~ "one",
                                    last_new_job == "never" ~ "never",
                                    TRUE ~ "two")) %>% 
            mutate(company_type = case_when(
                                  company_type %in% c("Early Stage Startup", "Funded Startup", "NGO", "Other", "Public Sector") ~ "other",
                                  company_type == "Pvt Ltd" ~ "pvtLtd")) %>% 
  mutate(relevant_experience = case_when(
                      relevant_experience == "Has relevent experience" ~ "yes",
                      relevant_experience == "No relevent experience" ~ "no"
  )) %>% 
  mutate_if(is.character, as.factor)
  
job_te = job_te %>% mutate(enrolled_university = case_when(
                                            enrolled_university == "no_enrollment" ~ "noEnroll",
                                            enrolled_university %in% c("Full time course", "Part time course") ~ "enrolled")) %>% 
              mutate(education_level = case_when(
                                        education_level %in% c("Masters", "Phd") ~ "aboveCollege",
                                        education_level %in% c("Primary School", "High School") ~ "noCollege",
                                        TRUE ~ "college")) %>% 
             mutate(major_discipline = case_when(
                                         major_discipline == "STEM" ~ "STEM",
                                         TRUE ~ "non_STEM")) %>% 
             mutate(experience = case_when(
                                  experience  == ">20" ~ "twenty",
                                  experience == "<1" ~ "one",
                                  TRUE ~ "oneTotwenty")) %>%
             mutate(company_size = case_when(
                                    company_size %in% c("<10","10/49","50-99","100-500") ~ "small",
                                    company_size %in% c("500-999","1000-4999", "5000-9999") ~ "medium",
                                    TRUE ~ "big"))%>% 
             mutate(last_new_job = case_when(
                                    last_new_job == "1" ~ "one",
                                    last_new_job == "never" ~ "never",
                                    TRUE ~ "two")) %>% 
            mutate(company_type = case_when(
                                  company_type %in% c("Early Stage Startup", "Funded Startup", "NGO", "Other", "Public Sector") ~ "other",
                                  company_type == "Pvt Ltd" ~ "pvtLtd")) %>% 
  mutate(relevant_experience = case_when(
                      relevant_experience == "Has relevent experience" ~ "yes",
                      relevant_experience == "No relevent experience" ~ "no"
  )) %>% 
  mutate_if(is.character, as.factor)


tab2 <- tableby(target ~ relevant_experience+enrolled_university+education_level+major_discipline+experience+company_size+company_type+last_new_job+gender, data=rbind(job_tr,job_te))
summary(tab2, title = "Descriptive Statistics: Job Change",  text=T)
```


### Visualization of continuous variables        
From the density curve of city_development_index and training hours for different outcomes[figure2], it can be seen that city_development_index might play an important role in predicting the outcome.

```{r include=TRUE, message=FALSE}

theme1 <- transparentTheme(trans = .4)
trellis.par.set(theme1)

full_data = rbind(job_tr,job_te)

featurePlot(x = full_data[, c(1, 11)], 
            y = full_data$target,
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))
```


## Models

```{r include=TRUE, message=FALSE}
x_tr = model.matrix(target~., job_tr)[, -1]
y_tr = job_tr[,12]

x_te = model.matrix(target~., job_te)[, -1]
y_te = job_te[,12]
```


```{r include=TRUE, message=FALSE}
sample_1000 = sample_n(job_tr, 1000)

x_tr_1000 = model.matrix(target~., sample_1000)[, -1]
y_tr_1000 = sample_1000[, 12]
```


```{r include=TRUE, message=FALSE}
ctrl = trainControl(method = "cv",
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)
```


```{r include=TRUE, message=FALSE}
set.seed(2)
model.glm = train(x = x_tr_1000,
                  y = y_tr_1000,
                  method = 'glm',
                  metric = "ROC",
                 trControl = ctrl)
#We consider the simple classifier with a cut-off of 0.5 and evaluate its performance on the test data.

test.pred.prob = predict(model.glm, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.glm$bestTune

```

```{r include=TRUE, message=FALSE}

glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 6),
                        .lambda = exp(seq(-8, -2, length = 20)))
set.seed(2)
model.glmn <- train(x = x_tr_1000,
                    y = y_tr_1000,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl)
#We consider the simple classifier with a cut-off of 0.5 and evaluate its performance on the test data.

test.pred.prob = predict(model.glmn, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.glmn$bestTune
```


```{r include=TRUE, message=FALSE}
set.seed(2)
model.gam <- train(x = x_tr_1000,
                   y = y_tr_1000,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

#We consider the simple classifier with a cut-off of 0.5 and evaluate its performance on the test data.

test.pred.prob = predict(model.gam, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.gam$bestTune
```



```{r include=TRUE, message=FALSE}
set.seed(2)
model.mars <- train(x = x_tr_1000,
                    y = y_tr_1000,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3, 
                                           nprune = 2:15),
                    metric = "ROC",
                    trControl = ctrl)

test.pred.prob = predict(model.mars, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.mars$bestTune

```



```{r include=TRUE, message=FALSE}
set.seed(2)
model.lda = train(x = x_tr_1000,
                  y = y_tr_1000,
                  method = "lda",
                  metric = "ROC",
                  trControl = ctrl)

test.pred.prob = predict(model.lda, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.lda$bestTune
```



```{r include=TRUE, message=FALSE}
set.seed(2)
model.qda = train(x = x_tr_1000,
                  y = y_tr_1000,
                  method = "qda",
                  metric = "ROC",
                  trControl = ctrl)

test.pred.prob = predict(model.qda, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.qda$bestTune
```

##################################

```{r include=TRUE, message=FALSE}

rf.grid <- expand.grid(mtry = 1:16,
                       splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(2)
model.rf <- train(x = x_tr_1000,
                  y = y_tr_1000,
                method = "ranger",
                tuneGrid = rf.grid,
                metric = "ROC",
                trControl = ctrl)

ggplot(model.rf, highlight = TRUE)

test.pred.prob = predict(model.rf, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.rf$bestTune
```


```{r include=TRUE, message=FALSE}
gbmA.grid <- expand.grid(n.trees = c(2000,3000,4000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.001,0.003,0.005),
                         n.minobsinnode = 1)
set.seed(2)
model.gbma <- train(x = x_tr_1000,
                  y = y_tr_1000,
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)

ggplot(model.gbma, highlight = TRUE)

test.pred.prob = predict(model.gbma, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.gbma$bestTune

```



```{r include=TRUE, message=FALSE}
set.seed(2)
model.svml <- train(x = x_tr_1000,
                  y = y_tr_1000, 
                  method = "svmLinear",
                  # preProcess = c("center", "scale"),
                  tuneGrid = data.frame(C = exp(seq(-2,5,len=20))),
                  trControl = ctrl)

plot(model.svml, highlight = TRUE, xTrans = log)

test.pred.prob = predict(model.svml, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.svml$bestTune
```


```{r include=TRUE, message=FALSE}
svmr.grid <- expand.grid(C = exp(seq(-1,4,len=10)),
                         sigma = exp(seq(-8,0,len=10)))

# tunes over both cost and sigma
set.seed(2)             
model.svmr <- train(x = x_tr_1000,
                  y = y_tr_1000,
                  method = "svmRadialSigma",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

plot(model.svmr, highlight = TRUE)

test.pred.prob = predict(model.svmr, newdata = x_te, type = "prob")[,1]
test.pred = rep("change", length(test.pred.prob))
test.pred[test.pred.prob<0.5] = "no_change"

confusionMatrix(data = as.factor(test.pred),
                reference = y_te,
                positive = "change")
model.svmr$bestTune
```


##########################################

```{r include=TRUE, message=FALSE}

res <- resamples(list(GLM = model.glm, 
                      GLMNET = model.glmn, 
                      GAM = model.gam,
                      MARS = model.mars,
                      LDA = model.lda, 
                      QDA= model.qda,
                      rf = model.rf, 
                      gbma = model.gbma, 
                      svmr = model.svmr,
                      svml = model.svml))
summary(res)
bwplot(res, metric = "ROC")

```

### Predictors

I included all the 11 predictors -- 2 continuous variables (city_development_index and training_hours) and 8 catgorical variables(gender,relevant_experience,enrolled_university,education_level,major_discipline,experience,company_size,company_type,last_new_job) to built models.         
In the model building precess, I built 6 models: a logistic regression model, a penalized logistic regression model, a GAM model, a MARS model , a LDA model and  a QDA model.  I used caret to train all the six models and then made the comparison. 

### Technique
According to the result[figure3], the MARS model has the largest AUC, and thus became the final model I choose.

### Tuning parameters
There are two tuning parameters associated with the MARS model: the degree of interactions and the number of retained terms. I performed a grid(degree = 1:3,nprune = 2:15) search to identify the optimal combination of these hyperparameters that minimize prediction error. According to the result of cross validation[figure4], the best combination of tuning parameter would be:              
degree of interaction:1             
number of retained terms: 10

```{r include=TRUE, message=FALSE}
ggplot(model.gbma)
model.gbma$bestTune
coef(model.gbma$finalModel)
```

### Trainig/Testing performamce
 
For test dataset, I used the MARS model to make prediction on test dataset, then made a confusion matrix based on the predicted value and the true value. According to the ROC curve[figure5], the AUC for test data is 0.7645, the overall accuracy is 78.04%, and the Kappa is 0.3393, which had a moderate performance. The sensitivity is  0.40045 and the specificity is 0.90397. The training dataset, according to the result of resampling, has mean AUC 0.7594879, mean sensitivity 0.3910189 and mean specificity 0.9101620.

### Important variables

I used vip function to find the important variables. According to the result, the most important variable is "city_development_index", which aligned with the previous finding in visualization. Followed city development index is the relevant experiences. Besides, the vip result also showed that education_level:College and enrolled_university:enrolled also play important roles in predicting the outcome.

```{r include=TRUE, message=FALSE}

ggplot(model.gbma, highlight = TRUE)
summary(model.gbma$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```


### Partial Dependence Plot

```{r include=TRUE, message=FALSE}
p1 <- pdp::partial(model.gbma, pred.var = c("city_development_index"), grid.resolution = 10) %>% autoplot()
 p1
```


### Individual conditional expectation curve

```{r include=TRUE, message=FALSE}
ice1.gbma <- model.gbma %>% 
  partial(pred.var = "city_development_index", 
          grid.resolution = 100,
          ice = TRUE) %>%
  autoplot(train = x_tr_1000, alpha = .1) +
  ggtitle("ICE, not centered") 

ice2.gbma <- model.gbma %>% 
  partial(pred.var = "city_development_index", 
          grid.resolution = 100,
          ice = TRUE) %>%
  autoplot(train = x_tr_1000, alpha = .1, 
           center = TRUE) +
  ggtitle("ICE, centered") 


grid.arrange(ice1.gbma, ice2.gbma, nrow = 1)
```



### Limitation of the model

I think one of the problem of build a MARS model is the speed. During the model built process, the MARS model need the longest time to train.          
Besides speed, there is also the problem of global optimization vs. local optimization. The fitting process for MARS regression is done in a stepwise greedy manner. That way, only the best basis function given the current model is added/removed. So the model could be inaccurate if the local linear relationships are incorrect.


### Flexibility

I think the model is flexible enough to capture the underlying truth.

## Conclusions

According to the model, people have relevant experience in data science field, who has less than college education are more likely to change job.
According to the MARS model, city development index is the most important predictors for predicting whether the person want a new job or not(target).To better understand the relatioship between the features and the target, I created partial dependence plots for city_development_index. This is used to examine the marginal effects of predictors.



According to the plot, people live in the city with higher development index are more likely to change job, which make sense--high developed cities usually have more opportunities and challenges. People struggling in these kind of cities are mostly younger people who always seeking for better opportunities, and also they are more adaptable to changes.